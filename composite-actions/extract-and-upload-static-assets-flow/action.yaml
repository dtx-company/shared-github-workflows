name: extract-and-upload-static-assets-flow

inputs:
  service:
    required: true
    type: string
  image-tag:
    required: true
    type: string
  ecr-image-path:
    required: false
    description: "custom path to access the ECR docker image"
    type: string
  post-build-script-inputs:
    required: false
    description: "json string to pass to the post-build-script"
    type: string
  STATIC_ASSETS_S3_AWS_ACCESS_KEY_ID:
    required: true
    type: string
  STATIC_ASSETS_S3_AWS_SECRET_ACCESS_KEY:
    required: true
    type: string
  ECR_FLOWCODE_FC_DOCKER_SERVER:
    required: true
    type: string
  upload-sourcemaps:
    required: false
    description: "upload sourcemap files to DataDog"
    type: string
  DATADOG_API_KEY:
    required: false
    type: string

runs:
  using: "composite"
  steps:
    - name: Unset AWS creds env vars
      shell: bash
      run: |
        echo "AWS_ACCESS_KEY_ID=" >> $GITHUB_ENV
        echo "AWS_SECRET_ACCESS_KEY=" >> $GITHUB_ENV
        echo "AWS_SESSION_TOKEN=" >> $GITHUB_ENV
    - name: Setup Node.js
      if: inputs.upload-sourcemaps == 'true'
      uses: actions/setup-node@v3
      with:
        node-version: 16
    - uses: shrink/actions-docker-extract@v2
      id: assetExtract
      with:
        image: ${{ inputs.ECR_FLOWCODE_FC_DOCKER_SERVER }}/${{ inputs.service }}:${{inputs.ecr-image-path}}${{inputs.image-tag}}
        path: .next/static/.
    - name: Store json payload
      id: create-json
      uses: jsdaniell/create-json@v1.2.2
      with:
        name: "payload.json"
        json: ${{ inputs.post-build-script-inputs }}
    - name: Extract bucket name from post-build-inputs
      uses: sergeysova/jq-action@v2
      id: bucketExtract
      with:
        cmd: jq -r .s3bucket payload.json
        multiline: true
    - name: Upload Assets
      uses: keithweaver/aws-s3-github-action@v1.0.0
      with:
        command: sync
        source: ./${{ steps.assetExtract.outputs.destination }}
        destination: s3://${{ steps.bucketExtract.outputs.value }}/_next/static
        aws_access_key_id: ${{ inputs.STATIC_ASSETS_S3_AWS_ACCESS_KEY_ID }}
        aws_secret_access_key: ${{ inputs.STATIC_ASSETS_S3_AWS_SECRET_ACCESS_KEY }}
        aws_region: us-east-1
        aws_session_token: ""
    - name: Upload sourcemaps to DataDog
      if: inputs.upload-sourcemaps == 'true'
      shell: bash
      run: |
        DATADOG_API_KEY='${{ inputs.DATADOG_API_KEY }}' npx @datadog/datadog-ci sourcemaps upload ./${{ steps.assetExtract.outputs.destination }} \
        --service=${{ inputs.service }} \
        --release-version=${{ inputs.image-tag }} \
        --minified-path-prefix=https://app.flowcode.com/_next/static
